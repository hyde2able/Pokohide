<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ぽこひでブログ</title>
    <link>http://www.pokohide.me/categories/ruby/index.xml</link>
    <description>Recent content on ぽこひでブログ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <atom:link href="http://www.pokohide.me/categories/ruby/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>人工無能で会話してみた n-gram編(1)</title>
      <link>http://www.pokohide.me/blog/n-gram/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://www.pokohide.me/blog/n-gram/</guid>
      <description>&lt;p&gt;はじめまして。大学の前期授業も始まって今年から人工知能の講義があったので、試しに図書館にあったこの「はじめてのAIプログラミング」を読んでみました！&lt;/p&gt;

&lt;p&gt;実装はC言語なんですが、年明けからRubyを勉強し始めてからC言語の冗長性になんか嫌気がさしてしまったので、自分なりに拙いプログラムながらRubyで実装してみました。&lt;/p&gt;

&lt;p&gt;読んでみると「はじめて」とうたってるだけあって、最初の方はかなりわかりやすくて読んでいて楽しかったです。その内容を少しずつ紹介できたらなと思います。&lt;/p&gt;

&lt;p&gt;基本的にこの本の７割近くは人工無能の話で、人間と対話するにあたってどのような技術が使われてきたかをCのソース付きで解説してくれています。その中でも、最初に紹介されていたn-gram法とマルコフ連鎖を今日は自分のメモがてらここに。&lt;/p&gt;

&lt;p&gt;簡単な人工無能で会話するために、まず学習させる文章を用意します。夏目漱石とか古い感じの書籍だと著作権が切れてて無料でインターネットに載ってたりするので今回はそれを活用する。&lt;/p&gt;

&lt;p&gt;まず、その文章をn-gram法といって、n文字ずつのまとまりに区切ってその表れ方を解析する方法で、文章の特徴を知ります。例えば2-gram法で&lt;/p&gt;

&lt;p&gt;　　　　&lt;code&gt;「明日は晴れだ。」-&amp;gt; [明日],[日は],[は晴],[晴れ],[れだ],[だ。]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;と区切れます。この方法で区切ったこの2文字列を何か配列に格納して、2文字列が文章内に何回出現したかを記録していきます。これをつたないプログラムで書くと&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@list = {}
def ngram(n, text)
　i = 0
　while(text[i+n-1]) do
　　@list[text[i,n]]? (@list[text[i,n] += 1) : (@list[text[i,n]] = 1)
　　i += 1
　end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;となります。何らかの文章(text)と何文字ごとに分解するか(n)を引数で渡して、例えば3文字なら、3文字先の文字が存在しなくなるまで、while文で繰り返して、もし既にその3文字列が存在すれば+1を、まだ存在しなかったら1回出現したので1を格納する。といった動作をします。&lt;/p&gt;

&lt;p&gt;実際に実行してみると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ngram(2,&amp;quot;私は日本人です。私は中国人です。あなたは何人ですか？&amp;quot;)
#=&amp;gt; {&amp;quot;私は&amp;quot;=&amp;gt;2, &amp;quot;は日&amp;quot;=&amp;gt;1, &amp;quot;日本&amp;quot;=&amp;gt;1, &amp;quot;本人&amp;quot;=&amp;gt;1, &amp;quot;人で&amp;quot;=&amp;gt;3, &amp;quot;です&amp;quot;=&amp;gt;3, &amp;quot;す。&amp;quot;=&amp;gt;2, &amp;quot;。私&amp;quot;=&amp;gt;1, &amp;quot;は中&amp;quot;=&amp;gt;1, &amp;quot;中国&amp;quot;=&amp;gt;1, &amp;quot;国人&amp;quot;=&amp;gt;1, &amp;quot;。あ&amp;quot;=&amp;gt;1, &amp;quot;あな&amp;quot;=&amp;gt;1, &amp;quot;なた&amp;quot;=&amp;gt;1, &amp;quot;たは&amp;quot;=&amp;gt;1, &amp;quot;は何&amp;quot;=&amp;gt;1, &amp;quot;何人&amp;quot;=&amp;gt;1, &amp;quot;すか&amp;quot;=&amp;gt;1, &amp;quot;か？&amp;quot;=&amp;gt;1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と@listに格納されるので、とりあずこれでn-gram法は完成ということで。
次回はこのn-gram法で作ったn文字列をマルコフ連鎖で繋げてそれっぽい？会話をできる人工無能を頑張って作りますっb&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>